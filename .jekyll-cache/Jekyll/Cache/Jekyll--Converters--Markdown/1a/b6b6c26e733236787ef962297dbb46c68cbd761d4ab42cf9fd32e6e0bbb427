I"in<p>整理自<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html">李宏毅教授 2020 机器学习课程</a></p>

<!-- TOC GFM -->

<ul>
  <li><a href="#regression">Regression</a></li>
  <li><a href="#example-application">Example Application</a>
      + <a href="#step-1-model">Step 1: Model</a></li>
  <li><a href="#basic-concept---where-does-the-error-come-from">Basic Concept - Where does the error come from?</a>
    <ul>
      <li><a href="#estimator">Estimator</a></li>
      <li><a href="#bias-and-variance-of-estimator">Bias and Variance of Estimator</a>
        <ul>
          <li><a href="#variance">Variance</a></li>
          <li><a href="#bias">Bias</a></li>
          <li><a href="#what-to-do-with-large-bias">What to do with large bias?</a></li>
        </ul>
      </li>
      <li><a href="#what-to-do-with-large-variance">What to do with large variance?</a></li>
      <li><a href="#model-selection">Model Selection</a></li>
      <li><a href="#cross-validation">Cross Validation</a>
        <ul>
          <li><a href="#n-fold-cross-validation">N-fold Cross Validation</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<!-- /TOC -->

<h2 id="regression">Regression</h2>

<ul>
  <li>Stock Market Forecast</li>
</ul>

<p>[f(“股票数据”) = Dow\ Jones\ Industrial\ Average\ at\ tomorrow]</p>

<ul>
  <li>Self-driving Car</li>
</ul>

<p>[f(“无人车的Sensor”) = 方向盘角度]</p>

<ul>
  <li>Recommendation</li>
</ul>

<p>[f(“使用者A\ \ 商品B”) = 购买可能性]</p>

<h2 id="example-application">Example Application</h2>

<ul>
  <li>
    <p>Estimating the Combat Power (CP) of a pokemon after evolution</p>

    <p>用$x$代表宝可梦，其中$x_{s}$代表宝可梦的名称，$x_{cp}$，$x_{w}$代表重量，$x_{h}$代表身高。</p>
  </li>
</ul>

<p>[f(“宝可梦的参数\rightarrow x”) = “CP\ after \ evolution \rightarrow y”]</p>

<h4 id="step-1-model">Step 1: Model</h4>

<ul>
  <li>
    <p>A set of function 去描述一个Model:</p>

\[y = b + w\cdot x_{cp}\]

    <p>$w$ and $b$ are parameters (can be any value), eg:</p>

\[f_1:y=10.0+9.0\cdot x_{cp} \\f_2:y=9.8 + 9.2\cdot x_{cp} \\f_3:y=-0.8-1.2\cdot x_{cp} \\......\]

    <p>用以上去描述宝可梦的函数式:</p>

\[f(x)="CP\ after\ evolution" \rightarrow y\]

    <p>这叫做 <strong>Linear model</strong>，</p>

\[y = b + \sum{w_ix_i}\]

    <p>其中，$x_i$：An attribute of input x, 用来描述 <code class="language-plaintext highlighter-rouge">feature</code>，$w_i$：weight，$b$: bias 。</p>
  </li>
  <li>
    <p>Step 2: Goodness of Function</p>

    <p>引入一些数据来作为 $y=b+w\cdot x_{cp}$ 的 input，比如，第一个数据为杰尼龟的数据，用$x^1$来表示第一个数据的数据集，对应的 output ，即卡咪龟的数据集，用 $\hat{y}^1$ 代表。其他数据以此类推。</p>

    <p>接下来的 Training Data 假设就是 10 只宝可梦。即，</p>

\[(x^1, \hat{y}^1)\\ (x^2, \hat{y}^2)\\... \\(x^{10}，\hat{y}^{10})\]

    <p>对应图像如下，</p>

    <p><img src="/assets/202006/2020-06-26-22-17-41.png" alt="figure1" /></p>

    <p>图中任意一点的值为 $(x^n_{cp}, \hat{y}^n)$。</p>

    <p>在有了 training data 以后，需要定义另一个Loss function $L$: 其中input 为对应的 function，output 即为 how bad it is，即：</p>

\[L(f) = L(w, b)\\ =\sum^{10}_{n=1}(\hat{y}^n - (b+w\cdot x^n_{cp}))^2\]

    <p>衡量参数的好坏, 即$w$ 和$b$ 的好坏，</p>

    <p>其中里面的括号中为 Estimated y based on input function，而 $\hat{y}^n$即为真实至，而$L(f)$则给出 Estimation error。</p>

    <p>$\sum$来 Sum over examples。</p>

    <p>图像为，</p>

    <p><img src="/assets/202006/2020-06-26-22-36-19.png" alt="figure2" /></p>
  </li>
  <li>
    <p>Step: Best Function</p>

    <p>在建立了 A set of function 之后，要 pick the BEST Function，</p>

\[\begin{aligned}f^{*}=&amp; \arg \min _{f} L(f) \\w^{*}, b^{*} &amp;=\arg \min _{w, b} L(w, b) \\&amp;=\arg \min _{w, b} \sum_{n=1}^{10}\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)^{2}\end{aligned}\]

    <p>可以利用 <strong>Gradient Descent</strong> 来解这个 function。</p>
  </li>
  <li>
    <p>Step 3: Gradient Descent，来解$w^{*}=\arg \min_{w}L(w)$</p>

    <ul>
      <li>Consider loss function $L(w)$ with one parameter w:
        <ul>
          <li>
            <p>首先随机选一个起始值 $w^0$</p>
          </li>
          <li>
            <p>Compute</p>

\[\left.\frac{dL}{dw}\right|_{w=w^0}\]

            <p>用图像来表示即为，</p>

            <p><img src="/assets/202006/2020-06-26-22-49-54.png" alt="figure3" /></p>

            <p>寻找下一个$w^1$的值，即为</p>

\[w^1 \leftarrow w^0 - \left.\eta \frac{dL}{dw}\right|_{w=w^0}\]

            <p>其中 $\eta$ 被称为 “<strong>learning rate</strong>“，越大学习速度越快。</p>
          </li>
          <li>
            <p>下一步重复 Compute 
  \(\left.\frac{dL}{dw}\right| _{w=w^1}\)</p>
          </li>
          <li>
            <p>… Many iterations ( T times )</p>

            <p>这时候的情况如下图：</p>

            <p><img src="/assets/202006/2020-06-26-23-00-53.png" alt="figure4" /></p>

            <p>这时获得了 <strong>Local optimal</strong> $\rightarrow w^T$，但注意是并非 <strong>Global optimal</strong> 。</p>
          </li>
        </ul>
      </li>
      <li>
        <p>如果有两个参数呢?</p>

        <p>对应公式如下，</p>

\[w^*, b^* = \arg \min_{w, b}L(w, b)\]

        <ul>
          <li>
            <p>随机 Pick an initial value $w^0, b^0$</p>
          </li>
          <li>
            <p>Compute</p>
          </li>
        </ul>

\[\left.\frac{\partial L}{\partial w}\right|_{w=w^{0}, b=b^{0}},\left.\frac{\partial L}{\partial b}\right|_{w=w^0, b=b^0}\]

        <ul>
          <li>分别更新 $w$ 与 $b$ 的值</li>
        </ul>

\[w^1 \leftarrow w^0 - \left.\eta\frac{\partial L}{\partial w}\right|_{w=w^0, b=b^0}\\ b^1 \leftarrow b^0 - \left.\eta\frac{\partial L}{\partial b}\right|_{w=w^0, b=b^0}\]

        <ul>
          <li>Compute</li>
        </ul>

\[\left.\frac{\partial L}{\partial w}\right|_{w=w^1, b=b^1}, \left.\frac{\partial L}{\partial b}\right|_{w=w^1, b=b^1}\]

        <ul>
          <li>再次更新 $w$，$b$ 的值</li>
        </ul>

\[w^2 \leftarrow w^1 - \left.\eta\frac{\partial L}{\partial w}\right|_{w=w^1, b=b^1}\\ b^2 \leftarrow b^1 - \left.\eta\frac{\partial L}{\partial b}\right|_{w=w^1, b=b^1}\]

        <ul>
          <li>
            <p>反复重复这个步骤最终获得 loss 相对比较小的 $w$ 和 $b$ 的值</p>
          </li>
          <li>
            <p>而 $\nabla L$ 即为 <strong>gradient</strong> ：</p>
          </li>
        </ul>

\[\nabla L=\left[\begin{array}{l}\frac{\partial L}{\partial w} \\ \frac{\partial L}{\partial b}\end{array}\right] _\text { gradient }\]

        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  其中，将两个偏微分排成一个 vector
</code></pre></div>        </div>

        <ul>
          <li>示意图如下，</li>
        </ul>

        <p><img src="/assets/202006/2020-06-27-13-42-50.png" alt="figure5" /></p>

        <p>其中每一次的 <strong>gradient</strong> 即为等高线的法线法向。</p>

        <ul>
          <li>但用这种方法，会出现问题，即如下图左侧所示，如果起点不同可能会找到不同的输出值，但实际上，利用这种方法是不会产生 <strong>local optimal</strong> 的</li>
        </ul>

        <p><img src="/assets/202006/2020-06-27_13-47-03.png" alt="figure6" /></p>

        <ul>
          <li>Formulation of $\partial L / \partial w$ and $\partial L / \partial b$，即为</li>
        </ul>

\[\begin{array}{l}L(w, b)=\sum_{n=1}^{10} ({\left.\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)^{2}} \\\\\frac{\partial L}{\partial w}=? \sum_{n=1}^{10} 2\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)\left(-x_{c p}^{n}\right) \\\\\frac{\partial L}{\partial b}=? \sum_{n=1}^{10} 2\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)(-1)\end{array}\]
      </li>
      <li>
        <p>How’s the results?</p>

        <p><img src="/assets/202006/2020-06-27-14-55-10.png" alt="figure6" /></p>

        <p>可以获得 Average Error on Training Data为，</p>

\[\sum_{n=1}^{10}e^n = 31.9\]
      </li>
      <li>
        <p>但是真正关心的应该是 <strong>Generalization</strong>，What we reaaly care about is the error on new data (testing data)</p>

        <p>于是又取了十只 Pokemon，情况如下</p>

        <p><img src="/assets/202006/2020-06-27-15-00-34.png" alt="figure7" /></p>

        <p>而新的数据中的 Average Error on Training Data 为 35.0</p>
      </li>
      <li>
        <p>How can we do better</p>

        <ul>
          <li>
            <p>从上图中可见在CP较低和较高的区域，拟合不好，于是我们选择令 Selecting another Model</p>

\[y = b+ w_1\cdot x_{cp}+w_2\cdot (x_{cp})^2\]

            <p>找出 Best function，这时</p>

\[b= -10.3, \\w_1=1.0, w_2=2.7*10^{-3}\\ \text{Average Error} = 18.4\]

            <p><img src="/assets/202006/2020-06-27_15-10-09.png" alt="figure8" /></p>

            <p>重新取 10 只 Pokemon 得出，Average Error = 18.4</p>
          </li>
          <li>
            <p>Better! Could it be even better?</p>

            <p>引入更复杂的model，</p>

\[y = b + w_1 \cdot x_{cp}+w_2\cdot (x_{cp})^2 + w_3\cdot (x_{cp})^3\]

            <p>找出 Best Function，</p>

\[b=6.4, w_1=0.66\\ w_2=4.3*10^{-3},\\ w_3=-1.8*1-^{-6}, \\Average Error = 15.3\]

            <p>同样重新取 10 只 Pokemon ，得出 Average Error = 18.1</p>

            <p><img src="/assets/202006/2020-06-27_15-17-30.png" alt="figure9" /></p>
          </li>
          <li>
            <p>用同样的方法，Try to make it better</p>

\[y = b + w_1\cdot x_{cp}+ w_2\cdot (x_{cp})^2 + w_3\cdot (x_{cp})^3 + w_4\cdot (x_{cp})^4\]

            <p>并获得图像，</p>

            <p><img src="/assets/202006/2020-06-27_15-21-53.png" alt="figure10" /></p>

            <p>这时的 Average Error = 14.9，但重新取 10 只 Average Error = 28.8 变得比之前更高了</p>
          </li>
          <li>
            <p>继续使用更加复杂的 Model，结果会变得更加糟糕</p>

\[y = b+w_1\cdot x_{cp} +w_2\cdot (x_{cp})^2 + w_3\cdot(x_{cp})^3 + w_4\cdot (x_{cp})^4 + w_5\cdot (x_{cp})^5\]

            <p><img src="/assets/202006/2020-06-27_20-54-10.png" alt="figure11" /></p>
          </li>
          <li>
            <p>分析这 5 个 Model，对这5次的 Training Data 的 Average Error 进行统计，如下图</p>

            <p><img src="/assets/202006/2020-06-27_20-59-37.png" alt="figure12" /></p>

            <p>这是因为更复杂的 Model 的 Function Space 会包含低级的 Model Space，如下图描述</p>

            <p><img src="/assets/202006/2020-06-27_21-04-39.png" alt="figure13" /></p>

            <p>但如果针对于，Testing Data，则情况会不同，</p>

            <p><img src="/assets/202006/2020-06-27_21-06-56.png" alt="figure14" /></p>

            <p>A more complex model does not always lead to better performance on <strong>testing data</strong>, This is <strong>Overfitting</strong>.</p>

            <p>而当 Model 的复杂程度在第 4 次和第 5 次时，就发生了 Overfitting。</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>What are the hiden factors?</p>

    <p>在计算CP值时，前面的 input 数据选用的只有杰尼龟一种，一旦要是，但是要去 make a more general model，就要考虑Pokemon的种类这一问题。</p>

    <p><img src="/assets/202006/2020-06-27_21-18-21.png" alt="figure15" /></p>

    <p>如何解决这个问题呢？</p>

    <ul>
      <li>
        <p>Back to step 1: Redesign the fuction set of the Model</p>

        <p>可以套用 <code class="language-plaintext highlighter-rouge">if</code> 语句：</p>

        <p><img src="/assets/202006/2020-06-27_21-21-42.png" alt="figure16" /></p>

        <p>接下来，我们需要将加入<code class="language-plaintext highlighter-rouge">if</code>语句的 Model 改写为 Linear model ($y=b+\sum{w_i x_i}$)：</p>

\[\begin{aligned}y=&amp; b_{1} \cdot \delta\left(x_{s}=\text { Pidgey }\right) \\&amp;+w_{1} \cdot \delta\left(x_{s}=\text { Pidgey }\right) x_{c p} \\&amp;+b_{2} \cdot \delta\left(x_{s}=\text { Weedle }\right) \\&amp;+w_{2} \cdot \delta\left(x_{s}=\text { Weedle }\right) x_{c p} \\&amp;+b_{3} \cdot \delta\left(x_{s}=\text { Caterpie }\right) \\&amp;+w_{3} \cdot \delta\left(x_{s}=\text { caterpie }\right) x_{c p} \\&amp;+b_{4} \cdot \delta\left(x_{s}=\text { Eevee }\right) \\&amp;+w_{4} \cdot \delta\left(x_{s}=\text { Eevee }\right) x_{c p}\end{aligned}\]

        <p>其中，</p>

\[\delta(x_s = Pidgey) \ \  \left\{\begin{array}{ll}=1 &amp; \text { If } x_{s}=\text { Pidgey } \\ =0 &amp; \text { otherwise }\end{array}\right.\]

        <p>这样就有:</p>

\[if \ x_s = Pidgey，\\ y = b_1 + w_1\cdot x_{cp}\]

        <p>其中，</p>

\[\delta(x_s = Pidgey)\]

        <p>这一项即为 Linear model 中的 $x_i$，也就是 <strong>feature</strong></p>

        <p>引入不同 $x_s$ 后的分析图像如下图，</p>

        <p><img src="/assets/202006/2020-06-27_21-40-34.png" alt="figure17" /></p>

        <p>从图中可见，不考虑伊布的曲线fit的不好，是因为伊布可以进化为不同的精灵，但其他宝可梦也有一些或多或少fit不好的情况，可能是进化时候加了一个 random number，但也可能不是 random number，也可能有其他factors</p>
      </li>
      <li>
        <p>Are there any other hidden factors？</p>

        <p><img src="/assets/202006/2020-06-27_21-47-07.png" alt="figure18" /></p>

        <p>对待这个问题，有可能是很多因素导致的，如 weight，HP 等等，那么如何解决这个问题呢？我们可以将所有的能考虑到因素加进去：</p>

        <p><img src="/assets/202006/2020-06-27_22-11-13.png" alt="figure19" /></p>

        <p>这么复杂的 Model 给出了很低的 Training Error = 1.9，但Testing Error 却非常糟糕 = 102.3，发生了严重的 Overfitting。</p>

        <p>解决这个问题，我们要引出下一个概念：</p>
      </li>
      <li>
        <p>Back to step 2: Regularization，重新定义我们的 Loss Function，将不好的去掉</p>

        <p>即在原有的 Loss function 后添加一项：</p>

\[L = \sum_n(\hat{y}^n - (b + \sum{w_i x_i}))^2 + \lambda \sum(w_i)^2\]

        <p>而这个 $\lambda\sum(w_i)^2$ 项，The functions with smaller w_i are better</p>

        <p><strong>Why smooth functions are preferred?</strong></p>

        <p>比如我们在 input $x_i$ 的基础上，增加为 $x_i + \Delta x_i$，则此时 对于 $y=b+\sum w_i x_i$ output 变为 $w_i\Delta x_i$，则当 $w_i$越小，input 对 output 影响越小，这样 function 也就会比较平滑</p>

        <p><strong>If some noises corrupt input $x_i$ when testing</strong>，也就是是说 function 如果变得不平滑了，A smoother function has less influence。</p>

        <p><img src="/assets/202006/2020-06-27_22-30-35.png" alt="figure20" /></p>

        <p>首先可以确定，当 $lambda$ 越大，function 越平滑，但 function 越平滑，Traning data error 越大，这是因为：<strong>Larger $lambda$，considering the training error less</strong>，越倾向于考虑 $w_i$ 本来的值。</p>

        <p>但 Testing error 却发生不同的变化，可见：<strong>We prefer smooth function, but don’t be too smooth</strong>。</p>

        <p>所以我们需要调整一个较好的 $\lambda$，这是非常重要的。</p>
      </li>
      <li>
        <p>另外需要注意的是，对于 Regularization 项：</p>

\[\lambda\sum(w_i)^2\]

        <p>只包含有 $w_i$，但却没有 $b$，其实在考虑 Regularization时，不需要考虑 bias。因为加 bias 只会对 function 进行平移，不会影响 function 的平滑度。</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Conclusion:</p>

    <ul>
      <li>
        <p>Gradient descent</p>

        <ul>
          <li>Following lectures: theory and tips</li>
        </ul>
      </li>
      <li>
        <p>Overfitting and Regularization</p>

        <ul>
          <li>Following lectures: more theory behind these</li>
        </ul>
      </li>
      <li>
        <p>We finally get average error = 11.1 on the testing data</p>
        <ul>
          <li>
            <p>How about another set of new data? Underestimate? Overestimate?</p>
          </li>
          <li>
            <p>Following lectures: validation 来解决上面的问题。</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="basic-concept---where-does-the-error-come-from">Basic Concept - Where does the error come from?</h2>

<p>在之前的实例中，我们发现选择不同的 Function Set，也就是选择不同的 Model，往往会给出不同的 Average error，而且越复杂的 Model，不见得会给出越低的 Error。</p>

<p><img src="/assets/202006/2020-06-28_21-22-38.png" alt="figure21" /></p>

<p>而其中 error 有两个来源：</p>

<ol>
  <li>来自于 “<strong>bias</strong>”</li>
  <li>以及 “<strong>variance</strong>”</li>
</ol>

<h3 id="estimator">Estimator</h3>

<p>对于一个 Estimator, 如</p>

<p>[\hat{y} = \hat{f}(\text{Pokemon CP})]</p>

<p>From this training data, we find $f^*$ ，那么有 <strong>$f^*$ is an estimator of $\hat{f}$</strong>。二者关系可以用下图表示，</p>

<p><img src="/assets/202006/2020-06-28_21-34-48.png" alt="figure22" /></p>

<p>靶标的中心点是 $\hat{f}$，而 $f^*$ 则在偏离靶中心的位置，而这个偏离，就是又 <strong>Bias</strong> 以及 <strong>Variance</strong> 共同决定的。</p>

<h3 id="bias-and-variance-of-estimator">Bias and Variance of Estimator</h3>

<ul>
  <li>
    <p>Estimate the mean of a variable x</p>

    <ul>
      <li>assume the mean of x is $\mu$</li>
      <li>assume the variance of x is $\sigma^2$</li>
    </ul>
  </li>
  <li>
    <p>Estimator of mean $\mu$</p>

    <ul>
      <li>
        <p>Sample N points: ${x^1, x^2, …, x^N}$</p>

\[m = \frac{1}{N}\sum_n{n^n} \neq \mu\]

        <p>这时 $m$ 和 $\mu$ 的值是不相等的，示意图如下</p>
      </li>
    </ul>

    <p><img src="/assets/202006/2020-06-28_23-07-07.png" alt="figure23" /></p>

    <ul>
      <li>
        <p>但是如果我们计算这些 $m$ 的期望值，就会得到我们想要的 $\mu$</p>

\[E[m] = E\biggl[\frac{1}{N}\sum_n x^n\biggr] = \frac{1}{N}\sum_n E[x^n] = \mu\]

        <p>这个问题就像打靶，每次打靶都会偏离中心，但当打靶次数足够多，最终这些偏离中心的打点的中心就是最终的期望。</p>
      </li>
      <li>
        <p>这个散布在期望周围, 散的有多开取决于 $m$ 的 <strong>Variance</strong> ，这个 Variance 的表达式为，</p>

\[Var[m] = \frac{\sigma^2}{N}\]

        <p><strong>Varicance depends on the number of samples</strong>，如图所示</p>

        <p><img src="/assets/202006/2020-06-29_09-40-36.png" alt="figure24" /></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Estimator of variance $\sigma^2$</p>

    <ul>
      <li>
        <p>Sample N points: {$x^1, x^2, …, x^N$}</p>

        <ol>
          <li>
            <p>首先估计 $m$ 的值，</p>

\[m = \frac{1}{N}\sum_n x^n\]
          </li>
          <li>
            <p>之后再计算估计 $s^2$，</p>

\[s^2 = \frac{1}{N}\sum_n (x^n - m)^2\]

            <p>这个 $s^2$ 可以用来估计 $\sigma^2$</p>
          </li>
        </ol>

        <p>但是，需要注意，这个对于 $\sigma ^2$ 的估计是<strong>Biased estimator</strong>，</p>

\[E[s^2] = \frac{N-1}{N} \sigma ^2\]

        <p>也就是说 $s^2$ 的期望值并不正好等于 $\sigma^2$ ，如果我们增加样本量，这一现象就会减轻：</p>

        <p><img src="/assets/202006/2020-06-29_10-03-27.png" alt="figure25" /></p>

        <p>用打靶来描述这件事情，如下图</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Parallel Universes</p>

    <p><img src="/assets/202006/2020-06-29_10-18-48.png" alt="figure26" /></p>

    <p>而打靶打的准或不准是由 <strong>Variance</strong> 和 <strong>Bias</strong> 两部分共同决定的。</p>
  </li>
</ul>

<h4 id="variance">Variance</h4>

<p>In all the universes, we are collecting (catching) 10 Pokemons as training data to find $f^*$</p>

<p><img src="/assets/202006/2020-06-29_10-24-39.png" alt="figure27" /></p>

<p>我们在不同宇宙中抓到的宝可梦是不一样的。</p>

<p>In different universes, we use the same model, but obtain different $f^*$</p>

<p><img src="/assets/202006/2020-06-29_10-28-31.png" alt="figure28" /></p>

<p>最终的结果如果我们用越来越复杂的 model ，就会给出越来越崩溃的结果,</p>

<p><img src="/assets/202006/2020-06-29_10-31-14.png" alt="figure29" /></p>

<p>而这几种越来越复杂的 model 所带来的混乱的情况，用打靶来形容，如下图所示，</p>

<p><img src="/assets/202006/2020-06-29_10-35-57.png" alt="figure30" /></p>

<p>可以看出，越简单的 model，对应的 Variance 越小，这可以认为是因为，<strong>Simpler model is less influenced by the sampled data</strong> 。可以考虑一个极端的例子：</p>

<p>[f(x) = c]</p>

<p>对于这个常值函数的 model，其 Variance = 0，不会受到 sampled data 影响。</p>

<h4 id="bias">Bias</h4>

<p>[E[f^*] = \overline{f}]</p>

<ul>
  <li>
    <p>Bias: If we average all the $f^*$, is it close to $\hat{f}$</p>

    <ul>
      <li>
        <p>先引入打靶问题，来描述 Bias 大小对于靶标的影响，</p>

        <p><img src="/assets/202006/2020-06-29_15-35-04.png" alt="figure31" /></p>

        <p>可见，如果 Bias 很小，即使数据很离散，其平均值 $\overline{f}$ 也会很接近 $\hat{f}$。</p>
      </li>
      <li>
        <p>下面需要确定一条 $\hat{y}$，我们只能先假设一个 $\hat{f}$</p>

        <p><img src="/assets/202006/2020-06-29_15-35-05.png" alt="figure32" /></p>
      </li>
      <li>
        <p>然后我们分别对不同复杂程度下的 model 给出的 $\overline{f}$ 与 $\hat{f}$ 之间的关系，如下图</p>

        <p><img src="/assets/202006/2020-06-29_15-47-58.png" alt="figure32" /></p>

        <ul>
          <li>
            <p>上图是描述一次的 Model，图中曲线标注情况如下：</p>

            <p><strong>Black curve: the true function $\hat{f}$</strong></p>

            <p><strong>Red curves: 5000 $f^*$</strong></p>

            <p><strong>Blue curve: the average of 5000 $f^* = \overline{f}$</strong></p>
          </li>
          <li>
            <p>当考虑一个较为复杂的三次 Model，如下图</p>

            <p><img src="/assets/202006/2020-06-29_16-06-38.png" alt="figure33" /></p>

            <p>虽然单独每一次和 $\hat{f}$ 可能相差很多，但平均下来与 $\hat{f}$ 却较为接近。</p>
          </li>
          <li>
            <p>当复杂程度继续升高，即考虑五次的 Model，$\overline{f}$ 则进一步趋近于 $\hat{f}$，如下图所示:</p>

            <p><img src="/assets/202006/2020-06-29_16-10-08.png" alt="figure34" /></p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>对于以上现象，可以从 <strong>function space</strong> 的角度来解释，即如果 Model 没有那么复杂，它对应的 function space 就相对较小，可能并没有包含 Target，如下图，</p>

<p><img src="/assets/202006/2020-06-29_16-14-02.png" alt="figure35" /></p>

<p>相反如果 Model 比较复杂，对应上述 5 次的 Model，其 function space 较大，就可能包含了 Target，如下图，</p>

<p><img src="/assets/202006/2020-06-29_16-17-16.png" alt="figure36" /></p>

<h4 id="what-to-do-with-large-bias">What to do with large bias?</h4>

<p>综合起来，存在两种 error，即：</p>

<ol>
  <li><strong>Error from bias</strong></li>
  <li><strong>Error from variance</strong></li>
</ol>

<p>这两种对应的 Error 的关系如下图，</p>

<p><img src="/assets/202006/2020-06-29_16-56-40.png" alt="figure37" /></p>

<p>而由于 bias 引起 Error，我们称之为 <strong>Underfitting</strong> ；由于 variance 引起的 Error，我们称之为 <strong>Overfitting</strong>。</p>

<ul>
  <li>
    <p>Diagnosis:</p>

    <ul>
      <li>
        <p>If your model cannot even fit the training examples, then you have large bias: <strong>Underfitting</strong></p>

        <p><img src="/assets/202006/2020-06-29_17-04-50.png" alt="figure38" /></p>
      </li>
      <li>
        <p>If you can fit the training data, but large error on testing data, then you probably have large variance: <strong>Overfitting</strong></p>
      </li>
    </ul>
  </li>
  <li>
    <p>For bias, redesign your model:</p>

    <ul>
      <li>
        <p>Add more features as input</p>
      </li>
      <li>
        <p>A more complex model</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="what-to-do-with-large-variance">What to do with large variance?</h3>

<ul>
  <li>
    <p>more data</p>

    <p><img src="/assets/202006/2020-06-29_17-08-27.png" alt="figure39" /></p>

    <p>It’s very effective, but not always practical. 也可以根据经验给一个经验的 Model</p>
  </li>
  <li>
    <p>Regularization</p>

    <p>通过 Regularization，使得曲线更加平滑，如下图所示：</p>

    <p><img src="/assets/202006/2020-06-29_17-12-27.png" alt="figure40" /></p>

    <p>但是这样做，<strong>会伤害到 bias</strong></p>
  </li>
</ul>

<h3 id="model-selection">Model Selection</h3>

<ul>
  <li>
    <p>There is usually a trade-off between bias and variance.</p>
  </li>
  <li>
    <p>Select a model that balances two kinds of error to minimize total error</p>
  </li>
  <li>
    <p>What you should NOT do:</p>

    <p><img src="/assets/202006/2020-06-29_17-17-13.png" alt="figure41" /></p>

    <p><strong>注意不要直接选择 Model 3，因为绿色的 Testing Set 本身有着自己的 bias，而与实际上的 橙色的 Testing Set 不同 ( $Err &gt; 0.5$ )。</strong></p>

    <p>为了更好的理解这个问题，给出下面的举例：<strong>Homework</strong> 中的情况</p>

    <p><img src="/assets/202006/2020-06-29_17-22-53.png" alt="figure42" /></p>

    <p>更好地理解，比如说小明在班级里排名第一，但在全校可能排不上名次。</p>

    <p>那么如何解决这个问题呢？</p>
  </li>
</ul>

<h3 id="cross-validation">Cross Validation</h3>

<p><img src="/assets/202006/2020-06-29_17-32-58.png" alt="figure43" /></p>

<ol>
  <li>可以将 Training Set，分成两部分，即 Training Set 和 Validation Set</li>
  <li>再通过新的 Training Set 计算出 Error 以后，选出最佳的 Model</li>
  <li>再将全部 Training Set 加进去，计算public Tesing Set 的 Error，这时的 Error 会比之前的 Error 更大，但更加接近真实的 private Testing Set。</li>
  <li>但不建议在知道 pulic Error 很大以后，再返回去修改前面的 Model，因为这样会引入这次 Public Testing Set 中的 bias。</li>
</ol>

<ul>
  <li>
    <p>Using the results of public testing data to tune your model</p>
  </li>
  <li>
    <p>You are making public set better than private set，在 public 看到的 performance 没办法反应在 private 上的 performance了</p>
  </li>
</ul>

<p>如果将 Training Set 分开 Validation Set 时，发现 Validation 的 bias 也有问题怎么处理呢？</p>

<h4 id="n-fold-cross-validation">N-fold Cross Validation</h4>

<p>如果你不相信某一次 Training 结果，可以按下图方式进行：</p>

<p><img src="/assets/202006/2020-06-29_17-44-42.png" alt="figure44" /></p>

<p>利用这种方法，根据三次实验后的 Average Error，再去进行比较。原则上，少去根据 Testing Set 调整 Model 的话，往往最终得到的 Testing Set 会比较小。</p>

:ET